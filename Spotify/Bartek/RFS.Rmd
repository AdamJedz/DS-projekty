---
title: "Projekt2_Bartek"
author: "Bartosz Adamiec"
date: "17 02 2020"
output: github_document
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#install.packages('caret')
library(dplyr)
library(lubridate)
library(ggplot2)
library(tidyverse)
library(kableExtra)
library(ggthemes)
library(corrplot)
```

```{r load_and_prep}
# Random Forest 

#environment preparation and data load
my_theme <- theme_fivethirtyeight() + theme(axis.title = element_text(), axis.title.x = element_text())

mydata_train <- read.csv("../train_set.csv", stringsAsFactors = FALSE, na.strings="")

mydata_test <- read.csv("../test_set.csv", stringsAsFactors = FALSE, na.strings="")

lf_train <- mydata_train %>% select(playlist_genre, track_popularity, danceability, energy, key, loudness, mode, speechiness, acousticness, instrumentalness, liveness, valence, tempo, duration_ms)

lf_test <- mydata_test %>% select(playlist_genre, track_popularity, danceability, energy, key, loudness, mode, speechiness, acousticness, instrumentalness, liveness, valence, tempo, duration_ms)



lf_train <- lf_train %>% mutate_if(is.character,as.factor)
lf_test <- lf_test %>% mutate_if(is.character,as.factor)


lf_train$duration_ms <- scale(lf_train$duration_ms)
lf_test$duration_ms <- scale(lf_test$duration_ms)

str(lf_train)
```



```{r rf}

# Fitting Random Forest Classification to the Training set
#install.packages('randomForest')
#removing as those collumns are not really important
lf_train$key <- NULL
lf_test$key <- NULL
lf_train$mode <- NULL
lf_test$mode <- NULL

library(randomForest)
set.seed(123)
classifier = randomForest(x = lf_train[-1],
                          y = lf_train$playlist_genre,
                          ntree = 300,
                          )

# Predicting the Test set results
y_pred = predict(classifier, newdata = lf_test[-1])
```


```{r confusion_matrix}
# Making the Confusion Matrix
xtab <- table(y_pred, lf_test[, 1])
library(caret) 
confusionMatrix(xtab)
```

```{r importance_check}
#checking importance of each collumn
importance(classifier)

```



```{r plotting_classifier}
plot(classifier)
#getTree(classifier, k=1, labelVar=TRUE)
# library(ggplot2)
# pGenres <- predict(classifier,lf_test,'vote')
# plotData <- lapply(names(lf_test[,-1]), function(x){
#   out <- data.frame(
#     var = x,
#     type = c(rep('Actual',nrow(lf_test)),rep('Predicted',nrow(lf_test))),
#     value = c(lf_test[,x],lf_test[,x]),
#     genres = c(as.numeric(lf_test$playlist_genre)-1,pGenres)
#     )
#   out$value <- out$value-min(out$value) #Normalize to [0,1]
#   out$value <- out$value/max(out$value)
#   out
# })
# plotData <- do.call(rbind,plotData)
# qplot(value, genres, data=plotData, facets = type ~ var, geom='smooth', span = 0.5)
```


```{r rm_outliers}
#Random forest without outliers

out_dance <-boxplot(lf_train$danceability, plot=FALSE)$out
#out_popu <- boxplot(lf_train$track_popularity, plot=FALSE)$out
out_energy <- boxplot(lf_train$energy, plot=FALSE)$out
#out_key <- boxplot(lf_train$key, plot=FALSE)$out
out_loud <- boxplot(lf_train$loudness, plot=FALSE)$out
out_speech <- boxplot(lf_train$speechiness, plot=FALSE)$out
out_acoustic <- boxplot(lf_train$acousticness, plot=FALSE)$out
out_instrumental <- boxplot(lf_train$instrumentalness, plot=FALSE)$out
out_live <- boxplot(lf_train$liveness, plot=FALSE)$out
#out_valence <- boxplot(lf_train$valence, plot=FALSE)$out
out_tempo <- boxplot(lf_train$tempo, plot=FALSE)$out
out_duration <- boxplot(lf_train$duration_ms, plot=F)$out

#removed inserts where there was no outliers



outliers_help <- lf_train

outliers_help <- outliers_help[-which(outliers_help$danceability %in% out_dance),]
outliers_help <- outliers_help[-which(outliers_help$energy %in% out_energy),]
##outliers_help <- outliers_help[-which(outliers_help$loudness %in% out_loud),]
outliers_help <- outliers_help[-which(outliers_help$speechiness %in% out_speech),]
outliers_help <- outliers_help[-which(outliers_help$acousticness %in% out_acoustic),]
##outliers_help <- outliers_help[-which(outliers_help$instrumentalness %in% out_instrumental),]
outliers_help <- outliers_help[-which(outliers_help$liveness %in% out_live),]
outliers_help <- outliers_help[-which(outliers_help$tempo %in% out_tempo),]
outliers_help <- outliers_help[-which(outliers_help$duration_ms %in% out_duration),]



```


```{r rf_wo_outliers}
library(randomForest)
set.seed(123)
classifier2 = randomForest(x = outliers_help[-1],
                          y = outliers_help$playlist_genre,
                          ntree = 500)

# Predicting the Test set results
y_pred2 = predict(classifier2, newdata = lf_test[-1])
```


```{r cm_outliers}
# Making the Confusion Matrix
xtab2 <- table(y_pred2, lf_test[,1])
library(caret) 
confusionMatrix(xtab2)
```

-----------

```{r}
#the cross-validated prediction performance of models with sequentially reduced number of predictors (ranked by variable importance) via a nested cross-validation procedure
# set.seed(42)
# xD <- lf_train
# xD$playlist_genre <- NULL
# y <- lf_train$playlist_genre
# 
# rf.cv <- rfcv(xD, y, cv.fold=10)
# 
# with(rf.cv, plot(n.var, error.cv))

#takes 10 minutes to compile and I am not actually sure what does it show tbh
#?rfcv()
```

<!-- # ```{r} -->
<!-- # -->
<!-- # library(randomForest) -->
<!-- # #install.packages('mlbench') -->
<!-- # library(mlbench) -->
<!-- # library(caret) -->
<!-- # -->
<!-- # # Load Dataset -->
<!-- # dataset <- lf_train -->
<!-- # x <- dataset[,-1] -->
<!-- # y <- dataset[,1] -->
<!-- # # Create model with default paramters -->
<!-- # control <- trainControl(method="repeatedcv", number=10, repeats=3) -->
<!-- # seed <- 7 -->
<!-- # metric <- "Accuracy" -->
<!-- # set.seed(seed) -->
<!-- # mtry <- sqrt(ncol(x)) -->
<!-- # tunegrid <- expand.grid(.mtry=mtry) -->
<!-- # rf_default <- train(playlist_genre~., data=dataset, method="rf", metric=metric, tuneGrid=tunegrid, -->
<!-- #                     trControl=control) -->
<!-- # print(rf_default) -->
<!-- # ``` -->

<!-- # ```{r xd} -->
<!-- # -->
<!-- # customRF <- list(type = "Classification", library = "randomForest", loop = NULL) -->
<!-- # customRF$parameters <- data.frame(parameter = c("mtry", "ntree"), class = rep("numeric", 2), -->
<!-- #                                   label = c("mtry", "ntree")) -->
<!-- # customRF$grid <- function(x, y, len = NULL, search = "grid") {} -->
<!-- # customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) { -->
<!-- #   randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...) -->
<!-- # } -->
<!-- # customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL) -->
<!-- #    predict(modelFit, newdata) -->
<!-- # customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL) -->
<!-- #    predict(modelFit, newdata, type = "prob") -->
<!-- # customRF$sort <- function(x) x[order(x[,1]),] -->
<!-- # customRF$levels <- function(x) x$playlist_genre -->
<!-- # -->
<!-- # ``` -->

<!-- # ```{r xdd} -->
<!-- # -->
<!-- # # FINDING NTREE AND MTRY WITH HIGHEST ACCURACY -->
<!-- # -->
<!-- # # !!!!!!!!!!!!!!!!!!!!!!!!! -->
<!-- # # TAKES FOREVER TO COMPILE -->
<!-- # -->
<!-- # -->
<!-- # -->
<!-- # # control <- trainControl(method="repeatedcv", number=10, repeats=2) -->
<!-- # # tunegrid <- expand.grid(.mtry=c(1:5), .ntree=c(150, 300, 450, 600)) -->
<!-- # # set.seed(seed) -->
<!-- # # custom <- train(playlist_genre~., data=dataset, method=customRF, metric=metric, tuneGrid=tunegrid, -->
<!-- # #                 trControl=control) -->
<!-- # -->
<!-- # # custom -->
<!-- # # plot(custom) -->
<!-- # # mtry  ntree  Accuracy   Kappa -->
<!-- # # 4     450    0.5599259  0.4712420 -->
<!-- # ``` -->

```{r aa}
#ntree = 450 mtry = 4
set.seed(123)
classifier4 = randomForest(x = lf_train[-1],
                          y = lf_train$playlist_genre,
                          ntree = 450,
                          mtry = 4)

# Predicting the Test set results
y_pred4 = predict(classifier4, newdata = lf_test[-1])
```


```{r confusion_matrix2}
# Making the Confusion Matrix
xtab4 <- table(y_pred4, lf_test[, 1])
confusionMatrix(xtab4)

#tbh I do not know why accuracies differ but I guess it works
```


```{r}

rf.mdl <- randomForest(x = lf_train[-1],
                          y = lf_train$playlist_genre,
                          ntree = 450,
                          mtry = 4)
( rf.cv <- ??rf.crossValidation(rf.mdl, lf_train[-1], 
                              p=0.10, n=5, ntree=450) )
```

